{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\softwares\\anaconda\\envs\\lxz\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torchtext.data import get_tokenizer\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchtext.vocab import GloVe\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from keras.utils import np_utils\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('Combined_train.csv')\n",
    "df_valid = pd.read_csv('Combined_valid.csv')\n",
    "df_test = pd.read_csv('Combined_test.csv')\n",
    "\n",
    "start = 0\n",
    "end = 25\n",
    "# end = 1\n",
    "\n",
    "dataset = []\n",
    "for row in range(0,len(df_train.index)):\n",
    "    dataset.append(' '.join(str(x)[2:-1] for x in df_train.iloc[row,start+3:end+3]))\n",
    "train_size = len(dataset)\n",
    "for row in range(0,len(df_valid.index)):\n",
    "    dataset.append(' '.join(str(x)[2:-1] for x in df_valid.iloc[row,start+3:end+3]))\n",
    "valid_size = len(dataset) - train_size\n",
    "for row in range(0,len(df_test.index)):\n",
    "    dataset.append(' '.join(str(x)[2:-1] for x in df_test.iloc[row,start+3:end+3]))\n",
    "test_size = len(dataset) - train_size - valid_size\n",
    "\n",
    "acc_list = []\n",
    "name_list = []"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logic Regression 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data size (1591, 41004)\n",
      "valid data size: (199, 41004)\n",
      "test data size: (199, 41004)\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "all_data = vectorizer.fit_transform(dataset)\n",
    "train_data = all_data[:train_size]\n",
    "valid_data = all_data[train_size:train_size+valid_size]\n",
    "test_data = all_data[train_size+valid_size:]\n",
    "print(\"train data size\", train_data.shape)\n",
    "print(\"valid data size:\", valid_data.shape)\n",
    "print(\"test data size:\", test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\softwares\\anaconda\\envs\\lxz\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "model = model.fit(train_data, df_train[\"Label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logic Regression(basic) accuracy:  0.4623115577889447\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(test_data)\n",
    "acc1 = accuracy_score(df_test['Label'], preds)\n",
    "print('Logic Regression(basic) accuracy: ', acc1)\n",
    "# acc_list.append(acc1)\n",
    "# name_list.append(\"Logic Regression(basic)\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logic Regression 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input: the counts of phrases with two connected words(exclude words which are too common like \"a\" ,\"an\" ,\"the\" and words too uncommon of which counts are too small )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data size (1591, 595)\n",
      "valid data size: (199, 595)\n",
      "test data size: (199, 595)\n"
     ]
    }
   ],
   "source": [
    "advancedvectorizer = TfidfVectorizer( min_df=0.03, max_df=0.97, max_features = 200000, ngram_range = (2, 2))\n",
    "all_data = advancedvectorizer.fit_transform(dataset)\n",
    "train_data = all_data[:train_size]\n",
    "valid_data = all_data[train_size:train_size+valid_size]\n",
    "test_data = all_data[train_size+valid_size:]\n",
    "print(\"train data size\", train_data.shape)\n",
    "print(\"valid data size:\", valid_data.shape)\n",
    "print(\"test data size:\", test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid accuracy:  0.5728643216080402\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "model = model.fit(train_data, df_train[\"Label\"])\n",
    "preds = model.predict(valid_data)\n",
    "acc = accuracy_score(df_valid['Label'], preds)\n",
    "print('valid accuracy: ', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logic Regression accuracy:  0.5728643216080402\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(test_data)\n",
    "acc2 = accuracy_score(df_test['Label'], preds)\n",
    "print('Logic Regression accuracy: ', acc2)\n",
    "acc_list.append(acc2)\n",
    "name_list.append(\"LR\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data size (1591, 625)\n",
      "valid data size: (199, 625)\n",
      "test data size: (199, 625)\n"
     ]
    }
   ],
   "source": [
    "advancedvectorizer = TfidfVectorizer(min_df=0.03, max_df=0.5, max_features = 200000, ngram_range = (2, 3))\n",
    "all_data = advancedvectorizer.fit_transform(dataset)\n",
    "train_data = all_data[:train_size]\n",
    "valid_data = all_data[train_size:train_size+valid_size]\n",
    "test_data = all_data[train_size+valid_size:]\n",
    "print(\"train data size\", train_data.shape)\n",
    "print(\"valid data size:\", valid_data.shape)\n",
    "print(\"test data size:\", test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid accuracy:  0.5326633165829145\n"
     ]
    }
   ],
   "source": [
    "model = MultinomialNB(alpha=0.0001)\n",
    "model = model.fit(train_data, df_train[\"Label\"])\n",
    "preds = model.predict(valid_data)\n",
    "acc = accuracy_score(df_valid['Label'], preds)\n",
    "print('valid accuracy: ', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes accuracy:  0.6030150753768844\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(test_data)\n",
    "acc3 = accuracy_score(df_test['Label'], preds)\n",
    "print('Naive Bayes accuracy: ', acc3)\n",
    "acc_list.append(acc3)\n",
    "name_list.append(\"NB\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data size (1591, 625)\n",
      "valid data size: (199, 625)\n",
      "test data size: (199, 625)\n"
     ]
    }
   ],
   "source": [
    "advancedvectorizer = TfidfVectorizer(min_df=0.03, max_df=0.5, max_features = 200000, ngram_range = (2, 3))\n",
    "all_data = advancedvectorizer.fit_transform(dataset)\n",
    "train_data = all_data[:train_size]\n",
    "valid_data = all_data[train_size:train_size+valid_size]\n",
    "test_data = all_data[train_size+valid_size:]\n",
    "print(\"train data size\", train_data.shape)\n",
    "print(\"valid data size:\", valid_data.shape)\n",
    "print(\"test data size:\", test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid accuracy:  0.5577889447236181\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier()\n",
    "model = model.fit(train_data, df_train[\"Label\"])\n",
    "preds = model.predict(valid_data)\n",
    "acc = accuracy_score(df_valid['Label'], preds)\n",
    "print('valid accuracy: ', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest accuracy:  0.5678391959798995\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(test_data)\n",
    "acc4 = accuracy_score(df_test['Label'], preds)\n",
    "print('Random Forest accuracy: ', acc4)\n",
    "acc_list.append(acc4)\n",
    "name_list.append(\"RF\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data size (1591, 628)\n",
      "valid data size: (199, 628)\n",
      "test data size: (199, 628)\n"
     ]
    }
   ],
   "source": [
    "advancedvectorizer = TfidfVectorizer(min_df=0.03, max_df=0.9, max_features = 200000, ngram_range = (2, 3))\n",
    "all_data = advancedvectorizer.fit_transform(dataset)\n",
    "train_data = all_data[:train_size]\n",
    "valid_data = all_data[train_size:train_size+valid_size]\n",
    "test_data = all_data[train_size+valid_size:]\n",
    "print(\"train data size\", train_data.shape)\n",
    "print(\"valid data size:\", valid_data.shape)\n",
    "print(\"test data size:\", test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid accuracy:  0.5276381909547738\n"
     ]
    }
   ],
   "source": [
    "model = GradientBoostingClassifier()\n",
    "model = model.fit(train_data, df_train[\"Label\"])\n",
    "preds = model.predict(valid_data)\n",
    "acc = accuracy_score(df_valid['Label'], preds)\n",
    "print('valid accuracy: ', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBM accuracy:  0.47738693467336685\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(test_data)\n",
    "acc5 = accuracy_score(df_test['Label'], preds)\n",
    "print('GBM accuracy: ', acc5)\n",
    "acc_list.append(acc5)\n",
    "name_list.append(\"GBM\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic Gradient Descent Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data size (1591, 595)\n",
      "valid data size: (199, 595)\n",
      "test data size: (199, 595)\n"
     ]
    }
   ],
   "source": [
    "advancedvectorizer = TfidfVectorizer(min_df=0.03, max_df=0.9, max_features = 200000, ngram_range = (2, 2))\n",
    "all_data = advancedvectorizer.fit_transform(dataset)\n",
    "train_data = all_data[:train_size]\n",
    "valid_data = all_data[train_size:train_size+valid_size]\n",
    "test_data = all_data[train_size+valid_size:]\n",
    "print(\"train data size\", train_data.shape)\n",
    "print(\"valid data size:\", valid_data.shape)\n",
    "print(\"test data size:\", test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid accuracy:  0.5376884422110553\n"
     ]
    }
   ],
   "source": [
    "model = SGDClassifier(loss='modified_huber', random_state=0, shuffle=True)\n",
    "model = model.fit(train_data, df_train[\"Label\"])\n",
    "preds = model.predict(valid_data)\n",
    "acc = accuracy_score(df_valid['Label'], preds)\n",
    "print('valid accuracy: ', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDClassifier accuracy:  0.5125628140703518\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(test_data)\n",
    "acc6 = accuracy_score(df_test['Label'], preds)\n",
    "print('SGDClassifier accuracy: ', acc6)\n",
    "acc_list.append(acc6)\n",
    "name_list.append(\"SGD\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data size (1591, 628)\n",
      "valid data size: (199, 628)\n",
      "test data size: (199, 628)\n"
     ]
    }
   ],
   "source": [
    "advancedvectorizer = TfidfVectorizer(min_df=0.03, max_df=0.9, max_features = 200000, ngram_range = (2, 3))\n",
    "all_data = advancedvectorizer.fit_transform(dataset)\n",
    "train_data = all_data[:train_size]\n",
    "valid_data = all_data[train_size:train_size+valid_size]\n",
    "test_data = all_data[train_size+valid_size:]\n",
    "print(\"train data size\", train_data.shape)\n",
    "print(\"valid data size:\", valid_data.shape)\n",
    "print(\"test data size:\", test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid accuracy:  0.5376884422110553\n"
     ]
    }
   ],
   "source": [
    "model = SVC()\n",
    "model = model.fit(train_data, df_train[\"Label\"])\n",
    "preds = model.predict(valid_data)\n",
    "acc = accuracy_score(df_valid['Label'], preds)\n",
    "print('valid accuracy: ', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDClassifier accuracy:  0.6080402010050251\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(test_data)\n",
    "acc7 = accuracy_score(df_test['Label'], preds)\n",
    "print('SGDClassifier accuracy: ', acc7)\n",
    "acc_list.append(acc7)\n",
    "name_list.append(\"SVM\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data size (1591, 628)\n",
      "valid data size: (199, 628)\n",
      "test data size: (199, 628)\n"
     ]
    }
   ],
   "source": [
    "advancedvectorizer = TfidfVectorizer(min_df=0.03, max_df=0.9, max_features = 200000, ngram_range = (2, 3))\n",
    "all_data = advancedvectorizer.fit_transform(dataset)\n",
    "train_data = all_data[:train_size]\n",
    "valid_data = all_data[train_size:train_size+valid_size]\n",
    "test_data = all_data[train_size+valid_size:]\n",
    "print(\"train data size\", train_data.shape)\n",
    "print(\"valid data size:\", valid_data.shape)\n",
    "print(\"test data size:\", test_data.shape)\n",
    "\n",
    "X_train = train_data.toarray()\n",
    "X_test = test_data.toarray()\n",
    "y_train = np.array(df_train[\"Label\"])\n",
    "y_test = np.array(df_test[\"Label\"])\n",
    "\n",
    "Y_train = np_utils.to_categorical(y_train, 2)\n",
    "Y_test = np_utils.to_categorical(y_test, 2)\n",
    "\n",
    "scale = np.max(X_train)\n",
    "X_train /= scale\n",
    "X_test /= scale\n",
    "\n",
    "mean = np.mean(X_train)\n",
    "X_train -= mean\n",
    "X_test -= mean\n",
    "\n",
    "input_size = X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size=(256,128)):\n",
    "        super().__init__()\n",
    "\n",
    "        self.linear1 = nn.Linear(input_size, hidden_size[0])\n",
    "        self.drop1 = nn.Dropout(0.4)\n",
    "        self.linear2 = nn.Linear(hidden_size[0], hidden_size[1])\n",
    "        self.drop2 = nn.Dropout(0.4)\n",
    "        self.linear3 = nn.Linear(hidden_size[1], 2)\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        x = self.drop1(F.relu(self.linear1(x)))\n",
    "        x = self.drop2(F.relu(self.linear2(x)))\n",
    "        output = F.softmax(self.linear3(x), dim=-1)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPDataset(Dataset):\n",
    "    def __init__(self,data,label):\n",
    "        self.data = data\n",
    "        self.label = label\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        label = self.label[idx]\n",
    "        data = self.data[idx]\n",
    "\n",
    "        return data, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset\n",
    "train_dataset = MLPDataset(X_train,y_train)\n",
    "test_dataset = MLPDataset(X_test,y_test)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "# model\n",
    "device = 'cpu'\n",
    "model = MLP(input_size).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "citerion = torch.nn.CrossEntropyLoss(reduction=\"sum\")\n",
    "\n",
    "# setting\n",
    "num_epoch = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0. loss: 0.6929528713226318\n",
      "Epoch 1. loss: 0.6453937292098999\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "for epoch in range(num_epoch):\n",
    "    loss_sum = 0\n",
    "    dataset_len = len(train_dataloader.dataset)\n",
    "    for x, label in train_dataloader:\n",
    "        x = x.float().to(device)\n",
    "        label = label.to(device)\n",
    "        y = model(x)\n",
    "        loss = citerion(y, label)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_sum += loss\n",
    "    print(f'Epoch {epoch}. loss: {loss_sum / dataset_len}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP accuracy:  0.5979899497487438\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "preds = []\n",
    "model.eval()\n",
    "\n",
    "for x, label in test_dataloader:\n",
    "    x = x.float().to(device)\n",
    "    y = model(x)\n",
    "\n",
    "    y = torch.argmax(y)\n",
    "    preds.append(y.item())\n",
    "\n",
    "acc8 = accuracy_score(df_test['Label'], preds)\n",
    "print('MLP accuracy: ', acc8)\n",
    "acc_list.append(acc8)\n",
    "name_list.append(\"MLP\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN + Glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = dataset\n",
    "train_data = all_data[:train_size]\n",
    "valid_data = all_data[train_size:train_size+valid_size]\n",
    "test_data = all_data[train_size+valid_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNDataset(Dataset):\n",
    "    def __init__(self,data,label):\n",
    "        self.label = []\n",
    "        self.tokenize = get_tokenizer('basic_english')\n",
    "        self.glove = GloVe(name='6B', dim=300, cache=\"glove/\")\n",
    "\n",
    "        self.str2num = {0:[1,0], 1:[0,1]}\n",
    "\n",
    "        self.data = data\n",
    "        self.label = label\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sentence = self.tokenize(self.data[idx])\n",
    "        token = self.glove.get_vecs_by_tokens(sentence)\n",
    "\n",
    "        label = self.label[idx]\n",
    "        label = self.str2num[int(label)]\n",
    "\n",
    "        return token, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "def collate_fn(batch):\n",
    "    x, y = zip(*batch)\n",
    "    x_pad = pad_sequence(x, batch_first=True)\n",
    "    y = torch.Tensor(y)\n",
    "    return x_pad, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, hidden_units=64, dropout_rate=0.0):\n",
    "        super().__init__()\n",
    "        self.rnn = nn.GRU(300, hidden_units, num_layers = 1, batch_first=True, bidirectional=False, dropout=dropout_rate)\n",
    "        self.linear = nn.Linear(hidden_units, 2)\n",
    "\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        output, _ = self.rnn(x)\n",
    "        output = output[:, -1]\n",
    "        output = self.linear(output)\n",
    "\n",
    "        output = F.softmax(output, dim=-1)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset\n",
    "train_dataset = RNNDataset(train_data,df_train['Label'])\n",
    "test_dataset = RNNDataset(test_data,df_test['Label'])\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "# model\n",
    "device = 'cpu'\n",
    "model = RNN().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "citerion = torch.nn.CrossEntropyLoss(reduction=\"sum\")\n",
    "\n",
    "# setting\n",
    "num_epoch = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0. loss: 0.6937993168830872\n",
      "Epoch 1. loss: 0.6915706992149353\n",
      "Epoch 2. loss: 0.6874226331710815\n",
      "Epoch 3. loss: 0.6858598589897156\n",
      "Epoch 4. loss: 0.6877363324165344\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "for epoch in range(num_epoch):\n",
    "    loss_sum = 0\n",
    "    dataset_len = len(train_dataloader.dataset)\n",
    "    for x, label in train_dataloader:\n",
    "        x = x.to(device)\n",
    "        label = label.to(device)\n",
    "        y = model(x)\n",
    "        loss = citerion(y, label)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
    "        optimizer.step()\n",
    "        loss_sum += loss\n",
    "    print(f'Epoch {epoch}. loss: {loss_sum / dataset_len}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN accuracy:  0.5276381909547738\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "preds = []\n",
    "model.eval()\n",
    "\n",
    "for x, label in test_dataloader:\n",
    "    x = x.to(device)\n",
    "    y = model(x)\n",
    "\n",
    "    y = torch.argmax(y)\n",
    "    preds.append(y.item())\n",
    "\n",
    "acc9 = accuracy_score(df_test['Label'], preds)\n",
    "print('RNN accuracy: ', acc9)\n",
    "acc_list.append(acc9)\n",
    "name_list.append(\"RNN\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(name_list, acc_list)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lxz",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
